---
title: "R Tip of the Day"
subtitle: "The tmcn package"
author: "Nhi Luong"
date: "October 23, 2025"
format:
  revealjs:
    transition: slide
    background-transition: slide
    theme: default 
    slide-number: true
    chalkboard: 
      buttons: true
    preview-links: auto
editor_options: 
  chunk_output_type: console
---

```{r setup}
knitr::opts_chunk$set(include = TRUE, echo = TRUE)
```

```{r, echo=FALSE}
library(tidyverse)
library(wordcloud2)
library(tmcn)
library(tm)
library(readr)
library(dplyr)
library(tidytext)

data(GBK)
data("STOPWORDS")
```

## {auto-animate=true}

::: {style="margin-top: 200px; font-size: 2.5em"}
Let's explore **tmcn**!
:::

## Short Introduction {auto-animate=true; .smaller}
::: {style="margin-top: 80px;"}
The tmcn package is a text mining toolkit for the Chinese language.

- We can use functions from the package to:

::: incremental
  - Convert from Traditional Chinese to Simplified Chinese (and reverse)
  - Convert Chinese text to pinyin format
  - Output dictionary of Chinese stop words
  - Give some useful information about a character such as pinyin, radicals, stroke number of radical
:::

:::

## Convert Chinese text to Pinyin: **toPinyin()** {auto-animate=true}

::: {.fragment .fade-in}
* Pinyin is a romanized spelling of Chinese words. For example:
:::

::: {.fragment .fade-left}
* 妈妈 --> ma1ma1
:::

::: {.fragment .fade-left}
* 爸爸 --> ba4ba
:::

## Let's try it! {auto-animate=true}

```{r}
chinese_words <- c("爸爸","妈妈","圣奥拉夫","老师","学生","电脑","大学","秋季")
```

## Let's try it! {auto-animate=true}

```{r}
chinese_words <- c("爸爸","妈妈","圣奥拉夫","老师","学生","电脑","大学","秋季")
toPinyin(chinese_words)
```

## How about a table? {auto-animate=true; .smaller}

```{r, include=FALSE}
english_trans <- c("father","mother","Saint Olaf", "teacher", "student","computer","university","fall (season)")
chinese_words_pin <- toPinyin(chinese_words)
chinese_words_tbl <- 
  cbind(chinese_words, chinese_words_pin, english_trans) |> 
  as_tibble() |>
  rename("Chinese Words" = chinese_words,
         'Pinyin' = chinese_words_pin,
         "English Translation" = english_trans)
```

::: {.fragment}

::: {.center}
```{r, echo=FALSE}
knitr::kable(chinese_words_tbl[,1:3])
```
:::

:::

## Convert traditional to simplified: **toTrad()** {auto-animate=true}

```{r}
chinese_words <-c("爸爸","妈妈","圣奥拉夫","老师","学生","电脑","大学","秋季")
```

## Convert traditional to simplified: **toTrad()** {auto-animate=true}

```{r}
chinese_words <-c("爸爸","妈妈","圣奥拉夫","老师","学生","电脑","大学","秋季")
toTrad(chinese_words)
```

```{r, include=FALSE}
chinese_words_trad <- toTrad(chinese_words)
traditional_ex <- 
  cbind(chinese_words, chinese_words_trad, english_trans) |> 
  as_tibble() |>
  filter(chinese_words %in% c("妈妈","电脑")) |>
  rename(Simplified = chinese_words,
         Traditional = chinese_words_trad,
         'English Translation' = english_trans)
```

::: {.fragment .fade-up}
::: {.center}
```{r, echo=FALSE}
knitr::kable(traditional_ex[,1:3])
```
:::
:::


## Explore GBK Dataset {auto-animate=true; .smaller}

* GBK dataset provides users some useful information of a character such as pinyin, radical, stroke numbers of radical.

```{r}
GBK |>
  as_tibble() |>
  slice_head(n = 3)
```

## Explore GBK Dataset {auto-animate=true}

```{.r code-line-numbers="2|6|7-8"}
chinese_words_split <- c("爸","爸","妈","妈","圣","奥","拉","夫","老","师","学","生","电","脑","大","学","秋","季")
chinese_words_split |>
  as.tibble() |>
  distinct(value) |>
  inner_join(GBK, join_by(value == GBK)) |>
  slice_head(n = 5) |>
  select(1:5)
```

## Explore GBK Dataset {auto-animate=true; .smaller}

* GBK dataset provides users some useful information of a character such as pinyin, radicals, stroke numbers of radical.

```{r}
chinese_words_split <- c("爸","爸","妈","妈","圣","奥","拉","夫","老","师","学","生","电","脑","大","学","秋","季")
chinese_words_split |>
  as.tibble() |>
  distinct(value) |>
  inner_join(GBK, join_by(value == GBK)) |>
  slice_head(n = 5) |>
  select(1:5)
```

## In action! {auto-animate=true}
* "女" + "马" = "妈"

## In action! {auto-animate=true}
* "woman" + "horse" = "mother"
* "女" + "马" = "妈"

![](women_character.gif){.absolute .fragment top="250" left="30" width="400"}

![](mother_character.gif){.absolute .fragment top="250" right="80" width="400"}

```{r, echo=FALSE}
journey_west <- read_csv("~/SDS264_Presentations/Journey_to_the_west.csv")
```

## Journey to the West {auto-animate=true; .smaller}

::: {.fragment .fade-left}
- One of the most famous Chinese novels is "Journey to the West". Below is an excerpt from chapter 4.

```{r}
journey_west[[1]][1]
```
:::

::: {.fragment .fade-left}
- Looking at some Chinese stop words from STOPWORDS dataset

```{r}
head(STOPWORDS)
```
:::

::: footer
Link: [Journey to the West Novel](https://www.gutenberg.org/cache/epub/23962/pg23962-images.html)
:::

## Can we make a wordcloud for chapter 4? {auto-animate=true; .smaller}
::: panel-tabset
### Code

```{r,results='hide'}
journey_west_token <- journey_west |>
  unnest_tokens(word, "第五回 亂蟠桃大聖偷丹　反天宮諸神捉怪", token = "words")

journey_dfs <- journey_west_token |>
  anti_join(STOPWORDS) |>
  mutate(simplified = toTrad(word, rev = T)) |>
  count(simplified, sort = T) |>
  slice_head(n = 50) |>
  data.frame()

wordcloud2(
  journey_dfs, 
  size = 1.5, 
  shape = 'cardioid',
  minSize = 18
)
```

### Wordcloud

```{r, echo=FALSE}
wordcloud2(
  journey_dfs, 
  size = 1.5, 
  shape = 'cardioid',
  minSize = 10
)
```
:::


<!--

# Load in the data set containing first few paragraphs of Journey to the West

```{r}
journey_west <- read_csv("~/SDS264_Presentations/Journey_to_the_west.csv")
```

# Untoken to words

Here, I untoken all the sentences to one word per row. I remove stop words in column 'word' using STOPWORDS function in tmcn package.

```{r}
journey_west_token <- journey_west |>
  unnest_tokens(word, "第五回 亂蟠桃大聖偷丹　反天宮諸神捉怪", token = "words")

data("STOPWORDS")

journey_west_token |>
  anti_join(STOPWORDS) |>
  print(n = Inf) 
```

# Convert a Chinese text to pinyin format
Pinyin is a romanized spelling of Chinese words. Use to type out characters on computers. Here, we'll use the first row as example and apply the function toPinyin().

*Use tmcn*
```{r}
# Text from Journey to the West
toPinyin(journey_west[[1]][1])

# My own example words
chinese_words <- c("爸爸","妈妈","圣奥拉夫","老师","学生","电脑","大学","秋季")
toPinyin(chinese_words)

# Create a function to print out pinyin of a Chinese word

```

# Convert from traditional to simplify
We'll use the same example. We use function toTrad to convert the text. There is an argument called rev that takes TRUE and FALSE. TRUE means traditional to simplified.

```{r}
# Text from Journey to the West
#toTrad(first_row, rev = TRUE)

# My own example. This time convert from simplied to traditional
toTrad(chinese_words)
```

# Create a Chinese term-document matrix. COMEBACK

```{r}

```


# Create word frequency data.frame. COMEBACK
Here, we use function createWordFreq() to create a word frequency data.frame.

```{r}
#createWordFreq(first_row_token)
```

# Explore GBK function

```{r}
data(GBK)
chinese_words_split <- c("爸","爸","妈","妈","圣","奥","拉","夫","老","师","学","生","电","脑","大","学","秋","季")
chinese_words_split |>
  as.tibble() |>
  inner_join(GBK, join_by(value == GBK))
```

- Note: 
* Create a table here

# Explore Stroke number of radicals

- Note: Put in GIF that writes the characters
```{r}
journey_west_token |>
  mutate(simplified = toTrad(word, rev = T)) |>
  anti_join(STOPWORDS) |>
  inner_join(GBK, join_by(simplified == GBK)) |>
  arrange(desc(Stroke_Num_Radical))

```

# Explore National Taiwan University Semantic Dictionary
```{r}
data(NTUSD)
# Positive simplified
NTUSD$positive_chs |>
  as_tibble() |>
  inner_join(journey_west_token, join_by(value == word), relationship = "many-to-many")

# Convet Journy to the West to simplified first, then do inner join
positive_chs_tbl <- NTUSD$positive_chs |>
  as_tibble()
journey_west_token |>
  mutate(simplified = toTrad(word, rev = T)) |>
  inner_join(positive_chs_tbl, join_by(simplified == value))

# Negative simplified
NTUSD$negative_chs |>
  as.tibble() |>
  inner_join(journey_west_token, join_by(value == word)) |>
  print(n = Inf)

# Positive traditional
NTUSD$positive_cht |>
  as.tibble() |>
  inner_join(journey_west_token, join_by(value == word)) |>
  print(n = Inf)

# Negative traditional
NTUSD$negative_cht |>
  as.tibble() |>
  inner_join(journey_west_token, join_by(value == word)) |>
  count(value, sort = T)
```

- Observation: Since the tokenized words are traditional, it makes sense that we have more counts for positive and negative traditional words.

# Journey to the West wordcloud

```{r}
journey_dft <- journey_west_token |>
  anti_join(STOPWORDS) |>
  count(word, sort = T) |>
  slice_head(n = 50) |>
  data.frame()

wordcloud2(
  journey_dft, 
  size = 1, 
  shape = 'cardioid',
  minSize = 15
)

journey_dfs <- journey_west_token |>
  anti_join(STOPWORDS) |>
  mutate(simplified = toTrad(word, rev = T)) |>
  count(simplified, sort = T) |>
  slice_head(n = 50) |>
  data.frame()

wordcloud2(
  journey_dfs, 
  size = 1, 
  shape = 'cardioid',
  minSize = 15
)
```

# Thoughts on this package

- Very exciting to explore this package because I can combine my two interested fields together.
- The documentation for this package can include more explanations and exmaples on the functions.
- One suggestion could be to take the toPinyin function to a higher level, where we can see the four tones of the pinyin. It could be incorporated as part of the pinyin or a separate column just to highlight the tones.

# Test area

```{r}
journey_west_chr <- as.character(journey_west$`第五回 亂蟠桃大聖偷丹　反天宮諸神捉怪`)
toTrad(journey_west_chr, rev = T)
```

```{r}
journey_west_token |>
  mutate(simplified = toTrad(word, rev = T)) |>
  anti_join(STOPWORDS) |>
  count(simplified, sort = T) |>
  print(n = 50)
```

```{r}
#createWordFreq(as.vector(journey_west[1:2,], mode = "list"))
#as.vector(journey_west[1:2,], mode = "list")
```

```{r}

```

-->
